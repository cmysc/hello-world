{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_cifar10_load_drawActivations.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmysc/hello-world/blob/master/tf_cifar10_load_drawActivations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JYBhY4GghEjv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d65bf55f-6201-499f-b07b-22dba6f8c625"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline\n",
        "print(\"TensorFlow Version: %s\" % tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 1.12.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yEsyLzvHhH1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e7fd18e1-e967-4022-a88f-b5a8affbc5b5"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ETwvlyeViPgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "a96e4f3f-aa31-4b21-e1fb-8d0cc5e56a05"
      },
      "cell_type": "code",
      "source": [
        "ls'/content/drive/My Drive/0_neural_network/app/trained_model/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m100batchs\u001b[0m/\n",
            "\u001b[01;34m100batchs_0.55acc\u001b[0m/\n",
            "checkpoint\n",
            "tf_cifar10.data-00000-of-00001\n",
            "tf_cifar10_graphModified.data-00000-of-00001\n",
            "tf_cifar10_graphModified_EP50.data-00000-of-00001\n",
            "tf_cifar10_graphModified_EP50.index\n",
            "tf_cifar10_graphModified_EP50.meta\n",
            "tf_cifar10_graphModified.index\n",
            "tf_cifar10_graphModified.meta\n",
            "tf_cifar10.index\n",
            "tf_cifar10.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NK1PWDe5jF5C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loading data\n",
        "def load_cfar10_batch(load_cifar10_path, batch_id):\n",
        "   \n",
        "    with open(load_cifar10_path + 'data_batch_' + str(batch_id), mode='rb') as file:\n",
        "        batch = pickle.load(file , encoding='latin1')\n",
        "    \n",
        "    # features and labels\n",
        "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "    labels = batch['labels']\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "# for training set\n",
        "\n",
        "cifar10_path = '/content/drive/My Drive/0_neural_network/app/cifar-10-batches-py/'\n",
        "# 5 bactches\n",
        "x_train, y_train = load_cfar10_batch(cifar10_path,1)\n",
        "\n",
        "ba = [2,3]\n",
        "\n",
        "for i in ba: #range(2, 6):\n",
        "#for i in range(2, 6):\n",
        "    features, labels = load_cfar10_batch(cifar10_path, i)\n",
        "    x_train, y_train = np.concatenate([x_train, features]), np.concatenate([y_train, labels])\n",
        "\n",
        "# for testing set\n",
        "with open(cifar10_path + '/test_batch', mode='rb') as file:\n",
        "    batch = pickle.load(file , encoding='latin1')\n",
        "    x_test = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "    y_test = batch['labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m69VOR7Ejf1X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#normalization\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax = MinMaxScaler()\n",
        "\n",
        "# reshaope\n",
        "x_train_rows = x_train.reshape(x_train.shape[0], 32 * 32 * 3)\n",
        "x_test_rows = x_test.reshape(x_test.shape[0], 32 * 32 * 3)\n",
        "\n",
        "# scaling to (0,1)\n",
        "x_train = minmax.fit_transform(x_train_rows)\n",
        "x_test = minmax.fit_transform(x_test_rows)\n",
        "\n",
        "# reshape back32 x 32 x 3\n",
        "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
        "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lghpZT5tjlPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f795161-3c46-45dd-c87d-01cb5002db31"
      },
      "cell_type": "code",
      "source": [
        "#one-hot encoding\n",
        "from sklearn.preprocessing import LabelBinarizer #MultiLabelBinarizer#\n",
        "n_class = 10 #总共10类\n",
        "lb = LabelBinarizer().fit(np.array(range(n_class)))\n",
        "#lb = MultiLabelBinarizer().fit(np.array(range(n_class)))\n",
        "\n",
        "print((y_train.shape))\n",
        "\n",
        "y_train = lb.transform(y_train)\n",
        "y_test = lb.transform(y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TK-QFMdbjqnB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#split testing set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "test_ratio = 0.2\n",
        "\n",
        "x_test1, x_test2, y_test1, y_test2 = train_test_split(x_test, \n",
        "                                                      y_test, \n",
        "                                                      test_size=test_ratio,\n",
        "                                                      random_state=123)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TAHtKqKyjw3Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#inputs & labels (targets)\n",
        "inputs_ = tf.placeholder(tf.float32, [None, 32, 32, 3], name='inputs_')\n",
        "targets_ = tf.placeholder(tf.float32, [None, n_class], name='targets_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jCPgfmzUvUEc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getActivationImage(tensor, numNeuronConv,WidthHeight,drawFalseTrue):\n",
        "  temp = []\n",
        "  activationConvlayer = {}\n",
        "\n",
        "  for k in range(numNeuronConv):\n",
        "\n",
        "    temp = []\n",
        "    for i in range(WidthHeight):\n",
        "        inerList = []\n",
        "        for j in range(WidthHeight):\n",
        "            inerList.append( tensor[0][i][j][k]) #tensor[0] due to single image\n",
        "        # after inerList is scanned append to the outlist \"temp\"    \n",
        "        temp.append(inerList)\n",
        "    # after the square is created by scanning, make it to be numpy array and append to the Conv1_volume layer     \n",
        "    activationConvlayer[k] = np.array(temp)\n",
        "   \n",
        "    if drawFalseTrue:\n",
        "      fig = plt.figure(figsize=(6, 3.2))\n",
        "\n",
        "      ax = fig.add_subplot(111)\n",
        "      ax.set_title('colorMap')\n",
        "      print('k = ', k)\n",
        "      plt.imshow(activationConvlayer[k])\n",
        "\n",
        "      ax.set_aspect('equal')\n",
        "\n",
        "      cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
        "      cax.get_xaxis().set_visible(False)\n",
        "      cax.get_yaxis().set_visible(False)\n",
        "      #cax.patch.set_alpha(0)\n",
        "      cax.set_frame_on(False)\n",
        "      #plt.colorbar(orientation='vertical')\n",
        "      plt.show()\n",
        "  \n",
        "  return activationConvlayer\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BUbKTnwFSCdk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get single activation value of each ativation image from processed tensor\n",
        "\n",
        "\n",
        "def getSingleActivationValueVectorByAverage(tensor, numNeuronConv, WidthHeight):\n",
        "  activationValueVector = {}\n",
        "  for k in range(numNeuronConv):\n",
        "    sumTmp = 0.0\n",
        "    for i in range(WidthHeight):        \n",
        "        for j in range(WidthHeight):\n",
        "          sumTmp = float(tensor[0][i][j][k]) +sumTmp\n",
        "          \n",
        "    \n",
        "    activationValueVector.update({k:float(sumTmp)/WidthHeight/WidthHeight})\n",
        " \n",
        "  return activationValueVector\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tqnusPXyqhfW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import operator\n",
        "def imagesCollectionAfter_true_false_predict(imageIDcollection,imagID, pred,  drawFalseTrue):\n",
        "  # to seperate true and false predicted images into dictionary\n",
        "  \n",
        "  tempLayerDic = {}\n",
        "  activationValueInLayerDic = {}\n",
        "  IDmaxInLayer = {}\n",
        "  ValmaxInLayer ={}\n",
        "  layer = imageIDcollection[imagID]['raw_tensor']\n",
        "  \n",
        "  for layerIDStr, layerTensor in layer.items():\n",
        "    activationConvlayer = {}\n",
        "    activationConvlayer = getActivationImage(layerTensor,layerTensor.shape[3],layerTensor.shape[1],drawFalseTrue)\n",
        "    activationValueVector = getSingleActivationValueVectorByAverage(layerTensor,layerTensor.shape[3],layerTensor.shape[1])\n",
        "    \n",
        "    Key_maxActivationInLayer = max(activationValueVector.items(), key=operator.itemgetter(1))[0]\n",
        "    Val_maxActivationInLayer = max(activationValueVector.items(), key=operator.itemgetter(1))[1]\n",
        "\n",
        "    tempLayerDic.update({layerIDStr:activationConvlayer})\n",
        "    activationValueInLayerDic.update({layerIDStr:activationValueVector})\n",
        "    IDmaxInLayer.update({layerIDStr:Key_maxActivationInLayer})\n",
        "    ValmaxInLayer.update({layerIDStr:Val_maxActivationInLayer})\n",
        "    \n",
        "  \n",
        "  imageIDcollection[imagID]['processed_tensor'] = tempLayerDic\n",
        "  imageIDcollection[imagID]['activationValueInLayer'] = activationValueInLayerDic\n",
        "  imageIDcollection[imagID]['ID_maxActivationInLayer'] = IDmaxInLayer\n",
        "  imageIDcollection[imagID]['val_maxActivationInLayer'] = ValmaxInLayer\n",
        "  \n",
        "    \n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F8f8Ey-w8XPd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NumberOfImageForGraph = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2IChk48eg2ZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "e1ca9706-3641-4016-993c-70490195eb7e"
      },
      "cell_type": "code",
      "source": [
        "# testing\n",
        "# trained_model path\n",
        "save_model_path= '/content/drive/My Drive/0_neural_network/app/trained_model/tf_cifar10_graphModified'\n",
        "\n",
        "import random\n",
        "img_dict = {}  # data_array\n",
        "truePredList = []\n",
        "falsePredList = []\n",
        "imageIDactivationT = {}\n",
        "imageIDactivationF = {}\n",
        "\n",
        "layerName = ['input_image','conv1','conv2','pool2','conv3','conv4','pool4','conv5','conv6','pool6','fc1','fc2','output_pred']\n",
        "tf.reset_default_graph()\n",
        "loaded_graph = tf.Graph()\n",
        "test_batch_size= 1\n",
        "with tf.Session(graph=loaded_graph) as sess:\n",
        "  \n",
        "    # load model\n",
        "    \n",
        "    loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
        "    loader.restore(sess, save_model_path)\n",
        "   #loader.restore(sess, tf.train.latest_checkpoint('/content/drive/My Drive/0_neural_network/app/trained_model/'))\n",
        "\n",
        "    # load test_data tensor\n",
        "    loaded_x = loaded_graph.get_tensor_by_name('inputs_:0')        \n",
        "    loaded_y = loaded_graph.get_tensor_by_name('targets_:0')\n",
        "    \n",
        "    loaded_conv1 = loaded_graph.get_tensor_by_name('conv1/kernel:0')\n",
        "    loaded_conv2 = loaded_graph.get_tensor_by_name('conv2/kernel:0 ')\n",
        "    #loaded_pool2 = loaded_graph.get_tensor_by_name('pool2:0')\n",
        "    #pool2 = tf.layers.max_pooling2d(loaded_conv2, (2,2), (2,2),name='pool2')\n",
        "\n",
        "    loaded_conv3 = loaded_graph.get_tensor_by_name('conv3/kernel:0 ')\n",
        "    loaded_conv4 = loaded_graph.get_tensor_by_name('conv4/kernel:0 ')\n",
        "    #pool4 = tf.layers.max_pooling2d(loaded_conv4, (2,2), (2,2),name='pool4')\n",
        "    #dropout4 = loaded_graph.get_tensor_by_name('dropout4:0 ')\n",
        "\n",
        "    #loaded_pool4 = loaded_graph.get_tensor_by_name('pool4:0')\n",
        "    loaded_conv5 = loaded_graph.get_tensor_by_name('conv5/kernel:0 ')\n",
        "    loaded_conv6 = loaded_graph.get_tensor_by_name('conv6/kernel:0 ')\n",
        "    #pool6 = tf.layers.max_pooling2d(loaded_conv6, (2,2), (2,2),name='pool6')\n",
        "\n",
        "    loaded_fc1 = loaded_graph.get_tensor_by_name('fully_connected/weights:0')\n",
        "    loaded_fc2 = loaded_graph.get_tensor_by_name('fully_connected_1/weights:0')        \n",
        "    loaded_logits = loaded_graph.get_tensor_by_name('logits_:0')    \n",
        "    loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
        "    \n",
        "    \n",
        "    print ('weight and bias:\\n')\n",
        "    tvars = tf.trainable_variables()\n",
        "    tvars_vals = sess.run(tvars)\n",
        "    for var, val in zip(tvars, tvars_vals):\n",
        "       print(var.name, val.shape)\n",
        "       #print(var.name, val) \n",
        "    \n",
        "\n",
        "    # compute test_accuracy\n",
        "    test_batch_acc_total = 0\n",
        "    test_batch_count = 0\n",
        "    \n",
        "    print(\"Begin test...\" +str(x_test1.shape[0]))\n",
        "    for batch_i in range(x_test1.shape[0]//test_batch_size-8000+NumberOfImageForGraph):  #-1\n",
        "        test_feature_batch = x_test1[batch_i * test_batch_size: (batch_i+1)*test_batch_size]\n",
        "        test_label_batch = y_test1[batch_i * test_batch_size: (batch_i+1)*test_batch_size]\n",
        "        \n",
        "        test_image = sess.run(loaded_x ,  feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch})\n",
        "        ########### convolution computed manually to rebuid the cnn layers #########\n",
        "                \n",
        "        test_conv1 = tf.nn.convolution(test_image, sess.run(loaded_conv1), padding='SAME',strides=[1,1])   \n",
        "        res_test_conv1 = sess.run(test_conv1)\n",
        "        #print('res_test_conv1.shape')\n",
        "        #print(res_test_conv1.shape)\n",
        "                \n",
        "                      \n",
        "        test_conv2 = tf.nn.convolution(res_test_conv1, sess.run(loaded_conv2), padding='SAME',strides=[1,1])     \n",
        "        res_test_conv2 = sess.run(test_conv2)\n",
        "        #print('res_test_conv2.shape')\n",
        "        #print(res_test_conv2.shape)\n",
        "               \n",
        "        pool2 = tf.nn.max_pool(res_test_conv2,ksize=[1,2,2,1], strides=[1,2,2,1], padding = 'SAME',name='pool2')\n",
        "        res_test_pool2 = sess.run(pool2)\n",
        "        #print('pool2.shape')\n",
        "        #print(res_test_pool2.shape)\n",
        "        \n",
        "        test_conv3 = tf.nn.convolution(res_test_pool2, sess.run(loaded_conv3), padding='SAME',strides=[1,1])       \n",
        "        res_test_conv3 = sess.run(test_conv3)\n",
        "        #print('res_test_conv3.shape')\n",
        "        #print(res_test_conv3.shape)        \n",
        "       \n",
        "        test_conv4 = tf.nn.convolution(res_test_conv3, sess.run(loaded_conv4), padding='SAME',strides=[1,1])       \n",
        "        res_test_conv4 = sess.run(test_conv4)\n",
        "        #print('res_test_conv4.shape')\n",
        "        #print(res_test_conv4.shape)\n",
        "        \n",
        "        pool4 = tf.nn.max_pool(res_test_conv4,ksize=[1,2,2,1], strides=[1,2,2,1], padding = 'SAME',name='pool4')\n",
        "        res_test_pool4 = sess.run(pool4)\n",
        "        #print('pool4.shape')\n",
        "        #print(res_test_pool4.shape)\n",
        "        \n",
        "        test_conv5 = tf.nn.convolution(res_test_pool4, sess.run(loaded_conv5), padding='SAME',strides=[1,1])       \n",
        "        res_test_conv5 = sess.run(test_conv5)\n",
        "        #print('res_test_conv5.shape')\n",
        "        #print(res_test_conv5.shape)\n",
        "        \n",
        "        test_conv6 = tf.nn.convolution(res_test_conv5, sess.run(loaded_conv6), padding='SAME',strides=[1,1])       \n",
        "        res_test_conv6 = sess.run(test_conv6)\n",
        "        #print('res_test_conv6.shape')\n",
        "        #print(res_test_conv6.shape)\n",
        "        \n",
        "        pool6 = tf.nn.max_pool(res_test_conv6,ksize=[1,2,2,1], strides=[1,2,2,1], padding = 'SAME',name='pool6')\n",
        "        res_test_pool6 = sess.run(pool6)\n",
        "        #print('pool6.shape')\n",
        "        #print(res_test_pool6.shape)\n",
        "        \n",
        "        ###### fully connected not there\n",
        "        \n",
        "        \n",
        "        \n",
        "        ########\n",
        "        correct_pred = tf.equal(tf.argmax(loaded_logits, 1), tf.argmax(loaded_y, 1))\n",
        "        \n",
        "        test_correct_pred = sess.run(correct_pred,feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch})\n",
        "        #print(\"test_correct_pred: %s\" %(test_correct_pred[0]))\n",
        "        trueLabel = sess.run(tf.argmax(loaded_logits, 1), feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch})\n",
        "        #print(trueLabel)\n",
        "        prediLabel = sess.run(tf.argmax(loaded_y, 1),feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch})\n",
        "        #print(prediLabel)                              \n",
        "       \n",
        "        # classify the images to be false_pred and true_pred\n",
        "        #imagesCollectionAfter_true_false_predict(img_dict, truePredList, falsePredList, batch_i, test_correct_pred)\n",
        "        tempDic = {batch_i: {\n",
        "                            'raw_tensor':{\n",
        "                                          'test_input':test_image,\n",
        "                                          'test_conv1':res_test_conv1,\n",
        "                                          'test_conv2':res_test_conv2,\n",
        "                                          'test_pool2':res_test_pool2,\n",
        "                                          'test_conv3':res_test_conv3,\n",
        "                                          'test_conv4':res_test_conv4,\n",
        "                                          'test_pool4':res_test_pool4,\n",
        "                                          'test_conv5':res_test_conv5,\n",
        "                                          'test_conv6':res_test_conv6,\n",
        "                                          'test_pool6':res_test_pool6\n",
        "                                          },\n",
        "            \n",
        "                              'trueOrfalsePred': test_correct_pred[0],\n",
        "                              'trueLabel':trueLabel[0],\n",
        "                              'prediLabel':prediLabel[0]\n",
        "                            }\n",
        "                   }\n",
        "        img_dict.update(tempDic)\n",
        "       # print (img_dict)\n",
        "            \n",
        "        \n",
        "        ############### after got collection of image then print and see    \n",
        "        \n",
        "        # call imagesCollectionAfter_true_false_predict(imageIDcollection,imagID, pred0or1, truelabel, prediLabel, drawFalseTrue):        \n",
        "        imagesCollectionAfter_true_false_predict(img_dict, batch_i, test_correct_pred[0],  0)       \n",
        "        \n",
        "       \n",
        "        #print('------------')\n",
        "        ''' #structure in dictionary of img_dict\n",
        "        \"imageID: {'raw_tensor':{\n",
        "                                          'test_input':test_image,\n",
        "                                          'test_conv1':res_test_conv1,\n",
        "                                          'test_conv2':res_test_conv2,\n",
        "                                          'test_pool2':res_test_pool2,\n",
        "                                          'test_conv3':res_test_conv3,\n",
        "                                          'test_conv4':res_test_conv4,\n",
        "                                          'test_pool4':res_test_pool4,\n",
        "                                          'test_conv5':res_test_conv5,\n",
        "                                          'test_conv6':res_test_conv6,\n",
        "                                          'test_pool6':res_test_pool6\n",
        "                                          ###########\n",
        "                                          fully connected layer not included \n",
        "                                          },\n",
        "                   'processed_tensor':{\n",
        "                                          'test_input':test_image,\n",
        "                                          'test_conv1':res_test_conv1,\n",
        "                                          'test_conv2':res_test_conv2,\n",
        "                                          'test_pool2':res_test_pool2,\n",
        "                                          'test_conv3':res_test_conv3,\n",
        "                                          'test_conv4':res_test_conv4,\n",
        "                                          'test_pool4':res_test_pool4,\n",
        "                                          'test_conv5':res_test_conv5,\n",
        "                                          'test_conv6':res_test_conv6,\n",
        "                                          'test_pool6':res_test_pool6\n",
        "                                          },                       \n",
        "            \n",
        "                   'trueOrfalsePred': test_correct_pred,\n",
        "                    'trueLabel':tf.argmax(loaded_logits, 1), \n",
        "                    'prediLabel':tf.argmax(loaded_y, 1)\n",
        "         }\n",
        "        \n",
        "        '''\n",
        "        #print(img_dict)\n",
        "        \n",
        "      \n",
        "        \n",
        "        # to calculate average activation values\n",
        "       \n",
        "        \n",
        "\n",
        "        test_batch_acc_total += sess.run(\n",
        "            loaded_acc,\n",
        "            feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch})\n",
        "        test_batch_count += 1\n",
        "\n",
        "    print('Test Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
        "   \n",
        "    \n",
        "    "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/0_neural_network/app/trained_model/tf_cifar10_graphModified\n",
            "weight and bias:\n",
            "\n",
            "conv1/kernel:0 (3, 3, 3, 48)\n",
            "conv1/bias:0 (48,)\n",
            "conv2/kernel:0 (3, 3, 48, 48)\n",
            "conv2/bias:0 (48,)\n",
            "conv3/kernel:0 (3, 3, 48, 96)\n",
            "conv3/bias:0 (96,)\n",
            "conv4/kernel:0 (3, 3, 96, 96)\n",
            "conv4/bias:0 (96,)\n",
            "conv5/kernel:0 (3, 3, 96, 192)\n",
            "conv5/bias:0 (192,)\n",
            "conv6/kernel:0 (3, 3, 192, 192)\n",
            "conv6/bias:0 (192,)\n",
            "fully_connected/weights:0 (3072, 512)\n",
            "fully_connected/biases:0 (512,)\n",
            "fully_connected_1/weights:0 (512, 256)\n",
            "fully_connected_1/biases:0 (256,)\n",
            "fully_connected_2/weights:0 (256, 10)\n",
            "fully_connected_2/biases:0 (10,)\n",
            "Begin test...8000\n",
            "Test Accuracy: 0.46\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MGDjbrTh6N_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "82b75cdf-4fe6-4022-c2f6-db7d374e88df"
      },
      "cell_type": "code",
      "source": [
        "for k,v in img_dict[3].items():\n",
        "  if k == 'trueLabel':\n",
        "    print(v)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B1QpRX-PLxey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "2ec889e1-ff65-4580-ed3f-e927e9857f3a"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "for k,v in img_dict[0]['processed_tensor']['test_conv1'].items():\n",
        "  print(k)\n",
        "'''  \n",
        "  \n",
        "for k,v in img_dict[0]['val_maxActivationInLayer'].items():\n",
        "  print(k,v)\n",
        "print(img_dict[0]['ID_maxActivationInLayer'])\n",
        "print('------')\n",
        "#print((img_dict[0]['activationValueInLayer']))\n",
        "#print(type(img_dict))\n",
        "print('------')\n",
        "print((img_dict[0]['ID_maxActivationInLayer']['test_conv1']))\n",
        "print(len(img_dict[0]['processed_tensor']['test_conv1']))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_input 0.417792595651008\n",
            "test_conv1 0.489274482935798\n",
            "test_conv2 2.3454839914193144\n",
            "test_pool2 2.6481237314874306\n",
            "test_conv3 11.77508773189038\n",
            "test_conv4 173.73882625997066\n",
            "test_pool4 198.88404870033264\n",
            "test_conv5 1243.5569219589233\n",
            "test_conv6 39627.74526977539\n",
            "test_pool6 49317.5712890625\n",
            "{'test_input': 0, 'test_conv1': 8, 'test_conv2': 4, 'test_pool2': 4, 'test_conv3': 80, 'test_conv4': 35, 'test_pool4': 35, 'test_conv5': 116, 'test_conv6': 56, 'test_pool6': 56}\n",
            "------\n",
            "------\n",
            "8\n",
            "48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H1sQEVJOrBiI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#get flowOfNode maxActivation Node counting for each layer\n",
        "def getFlowOfNodeInLayer(classID,img_dict_, layerIDstr):\n",
        "  print(\"number of images: %s\" %(len(img_dict_)))\n",
        "  counter = 0\n",
        "  flowOfNodeInLayer ={}\n",
        "  tempCounterForEachNodeActivated = []\n",
        "  for i in range(len(img_dict_)):\n",
        "    if img_dict_[i]['trueLabel'] == classID: #img_dict_[i]['trueOrfalsePred'] ==1 and \n",
        "      counter+=1\n",
        "      tempCounterForEachNodeActivated.append(img_dict_[i]['ID_maxActivationInLayer'][layerIDstr])\n",
        "      #flowOfNodeInLayer[img_dict_[i]['ID_maxActivationInLayer'][layerIDstr]]=0\n",
        "\n",
        "      #print(img_dict_[i]['ID_maxActivationInLayer'][layerIDstr])\n",
        "  IDs = set(tempCounterForEachNodeActivated)\n",
        "  for id in IDs:\n",
        "    ct = 0 \n",
        "    for x in tempCounterForEachNodeActivated:\n",
        "      if x == id:\n",
        "        ct+=1\n",
        "    flowOfNodeInLayer[id] = ct\n",
        "    \n",
        "  #print(IDs)\n",
        "  print(\"number of corrected predicted images: %s\" %(counter))\n",
        "  print(flowOfNodeInLayer)\n",
        "  #print(tempCounterForEachNodeActivated)\n",
        "  #print(len(tempCounterForEachNodeActivated))\n",
        "  return flowOfNodeInLayer\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nqlyjAwDdBS8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "98b47708-1e56-41af-bfa4-559b69afe329"
      },
      "cell_type": "code",
      "source": [
        "# get how many number of neurons in each layer\n",
        "numNeuronLayer ={}\n",
        "for k,v in img_dict[0].items():\n",
        "  print(k)\n",
        "  #numNeuronLayer[k] = len(img_dict[0]['processed_tensor'][k])\n",
        "  \n",
        "print(numNeuronLayer) \n",
        "print(len(img_dict[0]['processed_tensor']))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw_tensor\n",
            "trueOrfalsePred\n",
            "trueLabel\n",
            "prediLabel\n",
            "processed_tensor\n",
            "activationValueInLayer\n",
            "ID_maxActivationInLayer\n",
            "val_maxActivationInLayer\n",
            "{}\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cFVK5TUrYuf4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Graph part"
      ]
    },
    {
      "metadata": {
        "id": "cVyw7ME_mdRa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "cnnG = nx.Graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8WHQse0PYpeS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "e856c826-a428-461d-a27d-2d254a7d4a00"
      },
      "cell_type": "code",
      "source": [
        "#parameters\n",
        "# nodes -----\n",
        "pos = {}\n",
        "attrSet = []\n",
        "labeldict = {} # make label with all nodes (neurons) 1,2, 3, ...\n",
        "color_map = []\n",
        "max_nodeValueInThisLayer = 0\n",
        "flowOfNode = {} # each node has a flow value\n",
        "\n",
        "#### for each layer add nodes and edges ###\n",
        "\n",
        "#for n in range(NumberOfImageForGraph):\n",
        "\n",
        "for k,v in img_dict[0]['processed_tensor'].items():\n",
        "  if k == 'test_input':\n",
        "    yPosInput =1\n",
        "    nodeCounter = 1\n",
        "    #----- image input -----\n",
        "    cnnG.add_node(nodeCounter,name ='inputImage',   pos = [0.5,yPosInput]) #size = activationInput['input'], it should be flowOfNode\n",
        "    attrSet.append(1) # flowOfNode for inputImage set to be one\n",
        "    pos[nodeCounter] = [0.5,yPosInput]\n",
        "    labeldict[1] = \"inputImage\"\n",
        "    color_map.append('red')\n",
        "    flowOfNode[1] = 1 # any number for the input Node ,randomly pick 1\n",
        "    \n",
        "  else: #----- other layers -----\n",
        "    nodeCounter = 1\n",
        "    temp = []\n",
        "    print(k)\n",
        "    flowOfNode = getFlowOfNodeInLayer(1,img_dict, k) #classID, img_dict, layerIDstr \n",
        "    \n",
        "    cnnG.add_node(nodeCounter,name ='inputImage',   pos = [0.5,yPosInput]) #size = activationInput['input'], it should be flowOfNode\n",
        "    \n",
        "    \n",
        "    '''\n",
        "    for key in sortedActConv1:\n",
        "        nodeCounter +=1\n",
        "        temp.append(sortedActConv1[key])\n",
        "        attrSet.append(sortedActConv1[key])    \n",
        "        #pos[key] = [1,i*2]\n",
        "        pos[nodeCounter] = [1,i*numNeuronConv2/numNeuronConv1]\n",
        "        labeldict[nodeCounter] = key\n",
        "        color_map.append('red')\n",
        "        i+=1    \n",
        "        cnnG.add_node(nodeCounter, name = key,size = sortedActConv1[key], pos = pos[nodeCounter])\n",
        "        cnnG.add_edge(1, nodeCounter)  \n",
        "\n",
        "    max_nodeValueInThisLayer = temp.index(max(temp))\n",
        "    #print max_nodeValueInThisLayer\n",
        "    #print temp\n",
        "    color_map[1+max_nodeValueInThisLayer] = 'green'\n",
        "    #print color_map\n",
        "    '''\n",
        "\n",
        "\n",
        "print(cnnG.node(data=True))\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_conv1\n",
            "number of images: 100\n",
            "number of corrected predicted images: 13\n",
            "{8: 13}\n",
            "test_conv2\n",
            "number of images: 100\n",
            "number of corrected predicted images: 13\n",
            "{4: 13}\n",
            "test_pool2\n",
            "number of images: 100\n",
            "number of corrected predicted images: 13\n",
            "{4: 13}\n",
            "test_conv3\n",
            "number of images: 100\n",
            "number of corrected predicted images: 13\n",
            "{80: 13}\n",
            "test_conv4\n",
            "number of images: 100\n",
            "number of corrected predicted images: 13\n",
            "{35: 13}\n",
            "test_pool4\n",
            "number of images: 100\n",
            "number of corrected predicted images: 13\n",
            "{35: 13}\n",
            "test_conv5\n",
            "number of images: 100\n",
            "number of corrected predicted images: 13\n",
            "{116: 13}\n",
            "test_conv6\n",
            "number of images: 100\n",
            "number of corrected predicted images: 13\n",
            "{56: 13}\n",
            "test_pool6\n",
            "number of images: 100\n",
            "number of corrected predicted images: 13\n",
            "{56: 13}\n",
            "[(1, {'name': 'inputImage', 'pos': [0.5, 1]})]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "45C4J2IuYphK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "f60ce70c-652a-434c-f720-06597c70d101"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plt.figure(1,figsize=(16,16))\n",
        "\n",
        "# rescale the size attribute of node\n",
        "enlargedAttrSet = [i * 500 for i in attrSet]\n",
        "\n",
        "nx.draw_networkx(cnnG, pos,  with_labels=True, node_size = enlargedAttrSet,node_color = color_map)#\n",
        "plt.draw()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6sAAAOFCAYAAACMRHTDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n42ZVkiRJktQ5blYlSZIkSZ3zD45o1VLYf3wVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7efead4ba2b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "cfnODr9CYpk7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vf-El9eQdBW2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "de15BuIcmdru"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kzBGuqTDbtj6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}